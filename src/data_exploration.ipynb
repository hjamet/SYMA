{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = os.path.join(\"..\", \"data\")\n",
    "\n",
    "train_session_df = pd.read_csv(os.path.join(PATH_DATA, \"train_sessions.csv\"))\n",
    "train_purchase_df = pd.read_csv(os.path.join(PATH_DATA, \"train_purchases.csv\"))\n",
    "\n",
    "candidate_items_df = pd.read_csv(os.path.join(PATH_DATA, \"candidate_items.csv\"))\n",
    "item_features_df = pd.read_csv(os.path.join(PATH_DATA, \"item_features.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.743820e+06</td>\n",
       "      <td>4.743820e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.218286e+06</td>\n",
       "      <td>1.402211e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.281012e+06</td>\n",
       "      <td>8.177893e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.110000e+06</td>\n",
       "      <td>6.946000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.214788e+06</td>\n",
       "      <td>1.403300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.325631e+06</td>\n",
       "      <td>2.100000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.440001e+06</td>\n",
       "      <td>2.814300e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         session_id       item_id\n",
       "count  4.743820e+06  4.743820e+06\n",
       "mean   2.218286e+06  1.402211e+04\n",
       "std    1.281012e+06  8.177893e+03\n",
       "min    3.000000e+00  2.000000e+00\n",
       "25%    1.110000e+06  6.946000e+03\n",
       "50%    2.214788e+06  1.403300e+04\n",
       "75%    3.325631e+06  2.100000e+04\n",
       "max    4.440001e+06  2.814300e+04"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_session_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.221071e+06</td>\n",
       "      <td>13978.825051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.281018e+06</td>\n",
       "      <td>8187.993593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.112741e+06</td>\n",
       "      <td>6977.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.220268e+06</td>\n",
       "      <td>13922.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.329927e+06</td>\n",
       "      <td>20879.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.440001e+06</td>\n",
       "      <td>28143.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         session_id         item_id\n",
       "count  1.000000e+06  1000000.000000\n",
       "mean   2.221071e+06    13978.825051\n",
       "std    1.281018e+06     8187.993593\n",
       "min    3.000000e+00        3.000000\n",
       "25%    1.112741e+06     6977.000000\n",
       "50%    2.220268e+06    13922.000000\n",
       "75%    3.329927e+06    20879.000000\n",
       "max    4.440001e+06    28143.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_purchase_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4990.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14007.035271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8218.231425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6833.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14108.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28137.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            item_id\n",
       "count   4990.000000\n",
       "mean   14007.035271\n",
       "std     8218.231425\n",
       "min        4.000000\n",
       "25%     6833.500000\n",
       "50%    14108.500000\n",
       "75%    21200.000000\n",
       "max    28137.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_items_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>feature_category_id</th>\n",
       "      <th>feature_value_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>471751.000000</td>\n",
       "      <td>471751.000000</td>\n",
       "      <td>471751.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14058.539477</td>\n",
       "      <td>42.424597</td>\n",
       "      <td>486.345578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8107.465455</td>\n",
       "      <td>22.186285</td>\n",
       "      <td>258.865151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7060.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>273.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14045.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>512.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21063.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>708.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28143.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>905.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             item_id  feature_category_id  feature_value_id\n",
       "count  471751.000000        471751.000000     471751.000000\n",
       "mean    14058.539477            42.424597        486.345578\n",
       "std      8107.465455            22.186285        258.865151\n",
       "min         2.000000             1.000000          1.000000\n",
       "25%      7060.000000            25.000000        273.000000\n",
       "50%     14045.000000            47.000000        512.000000\n",
       "75%     21063.000000            61.000000        708.000000\n",
       "max     28143.000000            73.000000        905.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How many different items does exist?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique item number : 23691\n",
      "Item id are unique :  True\n"
     ]
    }
   ],
   "source": [
    "distinct_item_number = len(item_features_df.item_id.unique())\n",
    "print(\"Unique item number :\", distinct_item_number)\n",
    "print(\"Item id are unique : \", item_features_df.item_id.nunique() == len(item_features_df.item_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How many different sessions does exist?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique user number : 1000000\n"
     ]
    }
   ],
   "source": [
    "distinct_session_number = len(pd.concat([train_session_df.session_id, train_purchase_df.session_id]).unique())\n",
    "print(\"Unique user number :\", distinct_session_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Does session always look an item before buying it?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A user never look at one item before buying it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "left_only     1000000\n",
       "right_only          0\n",
       "both                0\n",
       "Name: Exist, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"A user never look at one item before buying it.\")\n",
    "pd.merge(train_purchase_df, train_session_df, on=['session_id','item_id'], how='left', indicator='Exist')[\"Exist\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Can a session look at items without buying any?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every session bought exactly one item.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "both          4743820\n",
       "left_only           0\n",
       "right_only          0\n",
       "Name: Exist, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Every session bought exactly one item.\")\n",
    "\n",
    "pd.merge(train_purchase_df, train_session_df, on=['session_id'], how='left', indicator='Exist')[\"Exist\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What is the average number of different items every user usually look?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of items seen by user : 4.74382\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of items seen by user :\", train_session_df.groupby(\"session_id\").count()[\"item_id\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What will be the size of our rating matrix?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the maximum full rating matrix :  (23691000000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the maximum full rating matrix : \", (distinct_session_number * distinct_item_number, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create ratings given by every session for every item. We will first choose the following rating system:\n",
    "- If the user has seen the item, we will give it a rating of 1.\n",
    "- If the user purchased the item, we will give it a rating of 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.743820e+06</td>\n",
       "      <td>5.743820e+06</td>\n",
       "      <td>5.743820e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.218771e+06</td>\n",
       "      <td>1.401457e+04</td>\n",
       "      <td>1.174100e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.281013e+06</td>\n",
       "      <td>8.179668e+03</td>\n",
       "      <td>3.791956e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.110573e+06</td>\n",
       "      <td>6.952000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.215782e+06</td>\n",
       "      <td>1.401700e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.326251e+06</td>\n",
       "      <td>2.096900e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.440001e+06</td>\n",
       "      <td>2.814300e+04</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         session_id       item_id        rating\n",
       "count  5.743820e+06  5.743820e+06  5.743820e+06\n",
       "mean   2.218771e+06  1.401457e+04  1.174100e+00\n",
       "std    1.281013e+06  8.179668e+03  3.791956e-01\n",
       "min    3.000000e+00  2.000000e+00  1.000000e+00\n",
       "25%    1.110573e+06  6.952000e+03  1.000000e+00\n",
       "50%    2.215782e+06  1.401700e+04  1.000000e+00\n",
       "75%    3.326251e+06  2.096900e+04  1.000000e+00\n",
       "max    4.440001e+06  2.814300e+04  2.000000e+00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------- WE CREATE RATINGS ---------------------------- #\n",
    "train_rating_df = pd.concat([train_session_df.assign(rating=1), train_purchase_df.assign(rating=2)])\n",
    "train_rating_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- SHUFFLE AND RENAME ---------------------------- #\n",
    "train_ratings_df_shuffled = train_rating_df.sample(len(train_rating_df))\n",
    "train_ratings_df_shuffled.rename(columns={\"session_id\" : \"user_id\", \"rating\" : \"raw_ratings\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- WE REDUCE THE SIZE OF OUR DATASET FOR RESEARCH -------------- #\n",
    "\n",
    "train_set_df_reduced = train_ratings_df_shuffled[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- WE CREATE OUR SET ---------------------------- #\n",
    "\n",
    "import surprise\n",
    "\n",
    "rating_reader = surprise.Reader(rating_scale=(1, 2))\n",
    "dataset = surprise.dataset.Dataset.load_from_df(df=train_set_df_reduced[[\"user_id\", \"item_id\", \"raw_ratings\"]], reader=rating_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "import sklearn.model_selection\n",
    "\n",
    "train_set_df, test_set_df = sklearn.model_selection.train_test_split(train_set_df_reduced)\n",
    "\n",
    "rating_reader = surprise.Reader(rating_scale=(1, 2))\n",
    "train_set = surprise.dataset.Dataset.load_from_df(df=train_set_df[[\"user_id\", \"item_id\", \"raw_ratings\"]], reader=rating_reader)\n",
    "test_set = surprise.dataset.Dataset.load_from_df(df=test_set_df[[\"user_id\", \"item_id\", \"raw_ratings\"]], reader=rating_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.3893  0.3746  0.3664  0.3705  0.3797  0.3761  0.0079  \n",
      "MAE (testset)     0.2898  0.2821  0.2776  0.2790  0.2851  0.2827  0.0044  \n",
      "Fit time          0.39    0.38    0.34    0.36    0.34    0.36    0.02    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.38929695, 0.37464803, 0.36638123, 0.37048045, 0.37971612]),\n",
       " 'test_mae': array([0.28978332, 0.2820518 , 0.27760589, 0.27902141, 0.28514466]),\n",
       " 'fit_time': (0.3886566162109375,\n",
       "  0.3816335201263428,\n",
       "  0.3351600170135498,\n",
       "  0.3603065013885498,\n",
       "  0.3379371166229248),\n",
       " 'test_time': (0.013039112091064453,\n",
       "  0.007359504699707031,\n",
       "  0.007533073425292969,\n",
       "  0.0070400238037109375,\n",
       "  0.007886648178100586)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- WE TRAIN OUR FIRST MODEL ------------------------- #\n",
    "\n",
    "model = surprise.SVD()\n",
    "\n",
    "surprise.model_selection.cross_validate(model, train_set, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's compare our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "model_list = [surprise.NormalPredictor(), surprise.BaselineOnly(), surprise.KNNBaseline(), surprise.KNNBasic(), surprise.KNNWithMeans(), surprise.KNNWithZScore(), surprise.SlopeOne(), surprise.SVD(), surprise.SVDpp(), surprise.NMF(), surprise.CoClustering(), surprise.SlopeOne()]\n",
    "\n",
    "result = {}\n",
    "for model in model_list:\n",
    "    scores = surprise.model_selection.cross_validate(model, train_set, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=False)\n",
    "    result[model.__class__.__name__] = (scores[\"test_rmse\"].mean(), scores[\"test_mae\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('KNNBasic', (0.3756149370180923, 0.28216844444444444)),\n",
       " ('NMF', (0.37567029358443, 0.28165728130769346)),\n",
       " ('KNNWithZScore', (0.37570280584278837, 0.2816638222222222)),\n",
       " ('KNNWithMeans', (0.3758726344201063, 0.28182364444444447)),\n",
       " ('CoClustering', (0.3761587694225965, 0.2822100277982957)),\n",
       " ('KNNBaseline', (0.3762555199073618, 0.2828159731757588)),\n",
       " ('BaselineOnly', (0.37627617440355254, 0.2830257197443878)),\n",
       " ('SlopeOne', (0.37636238971266467, 0.28215519999999994)),\n",
       " ('SVD', (0.37653609601052046, 0.2831849467549553)),\n",
       " ('SVDpp', (0.3766360484081435, 0.2827790485735288)),\n",
       " ('NormalPredictor', (0.4721333813770521, 0.33600701838575764))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- BEST ALGORITHMS WITH RMSE ------------------------ #\n",
    "sorted(result.items(), key=lambda x: x[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NMF', (0.37567029358443, 0.28165728130769346)),\n",
       " ('KNNWithZScore', (0.37570280584278837, 0.2816638222222222)),\n",
       " ('KNNWithMeans', (0.3758726344201063, 0.28182364444444447)),\n",
       " ('SlopeOne', (0.37636238971266467, 0.28215519999999994)),\n",
       " ('KNNBasic', (0.3756149370180923, 0.28216844444444444)),\n",
       " ('CoClustering', (0.3761587694225965, 0.2822100277982957)),\n",
       " ('SVDpp', (0.3766360484081435, 0.2827790485735288)),\n",
       " ('KNNBaseline', (0.3762555199073618, 0.2828159731757588)),\n",
       " ('BaselineOnly', (0.37627617440355254, 0.2830257197443878)),\n",
       " ('SVD', (0.37653609601052046, 0.2831849467549553)),\n",
       " ('NormalPredictor', (0.4721333813770521, 0.33600701838575764))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- BEST ALGORITHMS WITH MAE ------------------------- #\n",
    "sorted(result.items(), key=lambda x: x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NMF', (0.37567029358443, 0.28165728130769346)),\n",
       " ('KNNWithZScore', (0.37570280584278837, 0.2816638222222222)),\n",
       " ('KNNWithMeans', (0.3758726344201063, 0.28182364444444447)),\n",
       " ('KNNBasic', (0.3756149370180923, 0.28216844444444444)),\n",
       " ('CoClustering', (0.3761587694225965, 0.2822100277982957)),\n",
       " ('SlopeOne', (0.37636238971266467, 0.28215519999999994)),\n",
       " ('KNNBaseline', (0.3762555199073618, 0.2828159731757588)),\n",
       " ('BaselineOnly', (0.37627617440355254, 0.2830257197443878)),\n",
       " ('SVDpp', (0.3766360484081435, 0.2827790485735288)),\n",
       " ('SVD', (0.37653609601052046, 0.2831849467549553)),\n",
       " ('NormalPredictor', (0.4721333813770521, 0.33600701838575764))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------ BEST ALGORITHMS ----------------------------- #\n",
    "import numpy as np\n",
    "sorted(result.items(), key=lambda x: np.mean(x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now perform some Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2846\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2633\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2408\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2197\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2846\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2633\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2408\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2197\n",
      "RMSE: 0.2854\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2624\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2412\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2208\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2861\n",
      "\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2624RMSE: 0.2437\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2208\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2855\n",
      "RMSE: 0.2630\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2407\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2234\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2851\n",
      "RMSE: 0.2627\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2392\n",
      "RMSE: 0.2216\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2845\n",
      "RMSE: 0.2627\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2396\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2211\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2858\n",
      "RMSE: 0.2620\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.4123\n",
      "RMSE: 0.2413\n",
      "RMSE: 0.2197\n",
      "RMSE: 0.4123\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- CREATING CROSS VALIDATION ------------------------ #\n",
    "\n",
    "import sklearn.model_selection\n",
    "from multiprocessing import Pool\n",
    "\n",
    "class MyCrossValidation():\n",
    "    def __init__(self, params):\n",
    "        self.SVD_list = [(surprise.SVD(**args), args) for args in list(sklearn.model_selection.ParameterGrid(params))]\n",
    "        self.full_train_set = train_set.build_full_trainset()\n",
    "\n",
    "    def __train_test_model(self, args):\n",
    "        svd_model, params = args\n",
    "        svd_model.fit(self.full_train_set)\n",
    "        predictions = svd_model.test(self.full_train_set.build_testset())\n",
    "        return (svd_model, params, surprise.accuracy.rmse(predictions))\n",
    "    \n",
    "    def __call__(self):\n",
    "        with Pool() as pool:\n",
    "            for svd_model, svd_params in self.SVD_list:\n",
    "                res = pool.map(self.__train_test_model, self.SVD_list)\n",
    "        return sorted(res, key=lambda x : x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f624b9f7160>,\n",
       " {'biased': True, 'n_factors': 200},\n",
       " 0.21965668734981583)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------- FIND BEST PARAMS ----------------------------- #\n",
    "params = {\n",
    "    \"biased\" : [True, False],\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9a52546c4e957e053486a924b19bc854fd75fae9b0430b0277efb1012ca5e24"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
